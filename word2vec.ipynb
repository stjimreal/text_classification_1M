{
 "cells": [
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用`CountVectorizer`简单的词向量化\n",
    "## 选择`min_df = 0.000001`去掉出现频率2篇以下的词汇\n",
    "## 选择`max_df = 0.4`去掉高频无用词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 549972 entries, 0 to 549971\nData columns (total 3 columns):\nindex      549972 non-null object\ncontent    549972 non-null object\ntag        549972 non-null object\ndtypes: object(3)\nmemory usage: 12.6+ MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 739840 entries, 0 to 739839\nData columns (total 3 columns):\nindex      739840 non-null object\ncontent    739840 non-null object\ntag        739840 non-null object\ndtypes: object(3)\nmemory usage: 16.9+ MB\nNone\n"
    },
    {
     "data": {
      "text/html": "<div>\n<style>\n    .dataframe thead tr:only-child th {\n        text-align: right;\n    }\n\n    .dataframe thead th {\n        text-align: left;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>content</th>\n      <th>tag</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>[标题, 月薪, 年头, 金融, 学历, 留学生, 月薪, 话题, 留学生, 高校, 毕业生...</td>\n      <td>教育</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>[综合报道, 澳大利亚, 节目, 事业, SBS, 报告, 英国, 政府, 外国, 留学生,...</td>\n      <td>教育</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>[中国, 行业, 论坛, 素质, 行业, 论坛, 总部, 大厦, 论坛, 主题, 行业, 素...</td>\n      <td>教育</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>[桃李, 芬芳, 书院, 时期, 潍坊, 一中, 时代, 面貌, 部长, 教育部, 党组, ...</td>\n      <td>教育</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>[渠道, ETS, 世贸, 媒体, 见面会, 媒体, 老师, 中国, 现状, 观点, ETS...</td>\n      <td>教育</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "  index                                            content tag\n0     1  [标题, 月薪, 年头, 金融, 学历, 留学生, 月薪, 话题, 留学生, 高校, 毕业生...  教育\n1     2  [综合报道, 澳大利亚, 节目, 事业, SBS, 报告, 英国, 政府, 外国, 留学生,...  教育\n2     3  [中国, 行业, 论坛, 素质, 行业, 论坛, 总部, 大厦, 论坛, 主题, 行业, 素...  教育\n3     4  [桃李, 芬芳, 书院, 时期, 潍坊, 一中, 时代, 面貌, 部长, 教育部, 党组, ...  教育\n4     5  [渠道, ETS, 世贸, 媒体, 见面会, 媒体, 老师, 中国, 现状, 观点, ETS...  教育"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "# 加载一个存好的pickles分词数组\n",
    "def openDataFrame(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        genList = pickle.load(f)\n",
    "        dbFrame = pd.DataFrame(genList, columns=['index', 'content', 'tag'])\n",
    "    return dbFrame\n",
    "\n",
    "trainFrame = openDataFrame('DB/trainDB/words.pkl')\n",
    "testFrame = openDataFrame('DB/testDB/words.pkl')\n",
    "print(trainFrame.info())\n",
    "print(testFrame.info())\n",
    "\n",
    "mergedFrame = pd.concat([trainFrame, testFrame])\n",
    "mergedFrame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到处理的词和数字化标签\n",
    "\n",
    "label_map = {'财经':0, '股票':1, '教育':2, '科技':3, '时政':4,'体育':5,'游戏':6,'娱乐':7,'汽车':8,'社会':9,'军事':10}\n",
    "mergedFrame['y_target'] = mergedFrame['tag'].map(label_map)\n",
    "y_target = mergedFrame.y_target.tolist()\n",
    "mergeList = [' '.join(x) for x in mergedFrame.content.tolist()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedFrame.to_csv('DB/raw/words.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(1289812, 4)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mergedFrame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": "(1289812, 469138)\n"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.feature_selection import chi2, SelectKBest\n",
    "\n",
    "vecMethod = CountVectorizer(min_df=0.000001, max_df=0.4)\n",
    "Matrix = vecMethod.fit_transform(mergeList)\n",
    "print(Matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "{0: '财经',\n 1: '股票',\n 2: '教育',\n 3: '科技',\n 4: '时政',\n 5: '体育',\n 6: '游戏',\n 7: '娱乐',\n 8: '汽车',\n 9: '社会',\n 10: '军事'}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relabel_map = {0:'财经', 1:'股票', 2:'教育', 3:'科技', 4:'时政', 5:'体育', 6:'游戏', 7:'娱乐', 8:'汽车', 9:'社会', 10:'军事'}\n",
    "relabel_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets.base import Bunch\n",
    "bunchObj = Bunch(matrix = Matrix, y_target = y_target, vocabulary = vecMethod.vocabulary_)\n",
    "with open('DB/matrix/BOW.pkl', 'xb') as f:\n",
    "    pickle.dump(bunchObj, f)"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}